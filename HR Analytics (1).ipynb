{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99ea2609-eb10-4e14-a69d-92b3e890cb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   satisfaction  evaluation  number_of_projects  average_montly_hours  \\\n",
      "0          0.38        0.53                   2                   157   \n",
      "1          0.80        0.86                   5                   262   \n",
      "2          0.11        0.88                   7                   272   \n",
      "3          0.72        0.87                   5                   223   \n",
      "4          0.37        0.52                   2                   159   \n",
      "\n",
      "   time_spend_company  work_accident  churn  promotion department  salary  \n",
      "0                   3              0      1          0      sales     low  \n",
      "1                   6              0      1          0      sales  medium  \n",
      "2                   4              0      1          0      sales  medium  \n",
      "3                   5              0      1          0      sales     low  \n",
      "4                   3              0      1          0      sales     low  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14999 entries, 0 to 14998\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   satisfaction          14999 non-null  float64\n",
      " 1   evaluation            14999 non-null  float64\n",
      " 2   number_of_projects    14999 non-null  int64  \n",
      " 3   average_montly_hours  14999 non-null  int64  \n",
      " 4   time_spend_company    14999 non-null  int64  \n",
      " 5   work_accident         14999 non-null  int64  \n",
      " 6   churn                 14999 non-null  int64  \n",
      " 7   promotion             14999 non-null  int64  \n",
      " 8   department            14999 non-null  object \n",
      " 9   salary                14999 non-null  object \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Import pandas (as pd) to read the data\n",
    "import pandas as pd\n",
    "\n",
    "# Read \"turnover.csv\" and save it in a DataFrame called data\n",
    "data = pd.read_csv(\"turnover_data.csv\")\n",
    "\n",
    "# Take a quick look to the first 5 rows of data\n",
    "print(data.head(5))\n",
    "\n",
    "# Get some information on the types of variables in data\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfa8c3f5-5ebc-4f3d-939e-5bfd6abc6e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sales' 'accounting' 'hr' 'technical' 'support' 'management' 'IT'\n",
      " 'product_mng' 'marketing' 'RandD']\n",
      "['low' 'medium' 'high']\n"
     ]
    }
   ],
   "source": [
    "# Print the unique values of the \"department\" column\n",
    "print(data.department.unique())\n",
    "\n",
    "# Print the unique values of the \"salary\" column\n",
    "print(data.salary.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b59e1ba8-bdea-4ebf-a22f-b7da120b7859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      IT  RandD  accounting     hr  management  marketing  product_mng  sales  \\\n",
      "0  False  False       False  False       False      False        False   True   \n",
      "1  False  False       False  False       False      False        False   True   \n",
      "2  False  False       False  False       False      False        False   True   \n",
      "3  False  False       False  False       False      False        False   True   \n",
      "4  False  False       False  False       False      False        False   True   \n",
      "\n",
      "   support  technical  \n",
      "0    False      False  \n",
      "1    False      False  \n",
      "2    False      False  \n",
      "3    False      False  \n",
      "4    False      False  \n"
     ]
    }
   ],
   "source": [
    "# Change the type of the \"salary\" column to categorical\n",
    "data.salary = data.salary.astype('category')\n",
    "\n",
    "data.salary = pd.Categorical(data.salary, categories=['low', 'medium', 'high'])\n",
    "\n",
    "# Provide the correct order of categories\n",
    "data.salary = data.salary.cat.reorder_categories(['low', 'medium', 'high'])\n",
    "\n",
    "# Encode categories\n",
    "data.salary = data.salary.cat.codes\n",
    "\n",
    "# Get dummies and save them inside a new DataFrame\n",
    "departments = pd.get_dummies(data.department)\n",
    "\n",
    "# Take a quick look to the first 5 rows of the new DataFrame called departments\n",
    "print(departments.head())\n",
    "\n",
    "# Drop the \"accounting\" column to avoid \"dummy trap\"\n",
    "departments = departments.drop(\"accounting\", axis=1)\n",
    "\n",
    "# Drop the old column \"department\" as you don't need it anymore\n",
    "data = data.drop(\"department\", axis=1)\n",
    "\n",
    "# Join the new DataFrame \"departments\" to your employee dataset: done\n",
    "data = data.join(departments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "519f460f-da94-4f06-b268-18994e59f355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn\n",
      "0    11428\n",
      "1     3571\n",
      "Name: count, dtype: int64\n",
      "churn\n",
      "0    76.191746\n",
      "1    23.808254\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Percentage of employees who Churn\n",
    "\n",
    "# Use len() function to get the total number of observations and save it as the number of employees\n",
    "n_employees = len(data)\n",
    "\n",
    "# Print the number of employees who left/stayed\n",
    "print(data.churn.value_counts())\n",
    "\n",
    "# Print the percentage of employees who left/stayed\n",
    "print(data.churn.value_counts()/n_employees * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "173abc5b-884c-4190-a24b-9263db1d5f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the target and features\n",
    "\n",
    "# Choose the dependent variable column (churn) and set it as target\n",
    "target = data.churn\n",
    "\n",
    "# Drop column churn and set everything else as features\n",
    "features = data.drop(\"churn\",axis=1)\n",
    "\n",
    "# Import the function for splitting dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use that function to create the splits both for target and for features\n",
    "# Set the test sample to be 25% of your observations\n",
    "target_train, target_test, features_train, features_test = train_test_split(target,features,test_size=0.25,random_state=42)\n",
    "\n",
    "# Import the classification algorithm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize it and call model by specifying the random_state parameter\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Apply a decision tree model to fit features to the target\n",
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3cafb8b-9e96-4b01-8d59-4492ad16a209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.22666666666666"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the Accuracy of the prediction\n",
    "\n",
    "# Apply a decision tree model to fit features to the target in the training set\n",
    "model.fit(features_train,target_train)\n",
    "\n",
    "# Check the accuracy score of the prediction for the training set\n",
    "model.score(features_train,target_train)*100\n",
    "\n",
    "# Check the accuracy score of the prediction for the test set\n",
    "model.score(features_test,target_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a370ee0-fdc5-4e47-8b2a-0fc66866d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exporting the Tree\n",
    "# Import the graphical visualization export function\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Apply Decision Tree model to fit Features to the Target\n",
    "model.fit(features_train,target_train)\n",
    "\n",
    "# Export the tree to a dot file\n",
    "export_graphviz(model,\"tree.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5fafdf6-8019-4c39-96da-b264563684f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.71535247577563\n",
      "97.06666666666666\n"
     ]
    }
   ],
   "source": [
    "#tuning turnover classifier\n",
    "# Initialize the DecisionTreeClassifier while limiting the depth of the tree to 5\n",
    "model_depth_5 = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model_depth_5.fit(features_train,target_train)\n",
    "\n",
    "# Print the accuracy of the prediction for the training set\n",
    "print(model_depth_5.score(features_train,target_train)*100)\n",
    "\n",
    "# Print the accuracy of the prediction for the test set\n",
    "print(model_depth_5.score(features_test,target_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bba8a8d0-bb22-41bc-84e9-cf7487cbb34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.57747355320473\n",
      "96.13333333333334\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DecisionTreeClassifier while limiting the sample size in leaves to 100\n",
    "model_sample_100 = DecisionTreeClassifier(min_samples_leaf = 100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model_sample_100.fit(features_train,target_train)\n",
    "\n",
    "# Print the accuracy of the prediction (in percentage points) for the training set\n",
    "print(model_sample_100.score(features_train,target_train)*100)\n",
    "\n",
    "# Print the accuracy of the prediction (in percentage points) for the test set\n",
    "print(model_sample_100.score(features_test,target_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f95218cd-ea19-415d-9bf6-4d8006c104b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9632107023411371"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating accuracy metrics: Recall\n",
    "# Import the function to calculate recall score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Use the initial model to predict churn\n",
    "prediction = model.predict(features_test)\n",
    "\n",
    "# Calculate recall score by comparing target_test with the prediction\n",
    "recall_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d04ec3c3-8029-4f13-ba2b-d11e94078095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9691623087590718"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating ROC/ AUC Score\n",
    "\n",
    "# Import the function to calculate ROC/AUC score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Use initial model to predict churn (based on features_test)\n",
    "prediction = model.predict(features_test)\n",
    "\n",
    "# Calculate ROC/AUC score by comparing target_test with the prediction\n",
    "roc_auc_score(target_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ff2e78a-e88e-4f0c-bb0b-152f830b015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.70666666666668\n"
     ]
    }
   ],
   "source": [
    "# Balancing Classes\n",
    "\n",
    "# Initialize the DecisionTreeClassifier \n",
    "model_depth_5_b = DecisionTreeClassifier(max_depth=5,class_weight=\"balanced\",random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "model_depth_5_b.fit(features_train,target_train)\n",
    "\n",
    "# Print the accuracy of the prediction (in percentage points) for the test set\n",
    "print(model_depth_5_b.score(features_test,target_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70051cb8-1af8-421b-879c-f54ecbafa238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for Imbalanced model\n",
      "0.9632107023411371\n",
      "0.9691623087590718\n",
      "Scores for Balanced model\n",
      "0.9319955406911928\n",
      "0.959863876199084\n"
     ]
    }
   ],
   "source": [
    "# Comparison of Employee Attrition Models\n",
    "\n",
    "# Print the recall score for imbalanced Model\n",
    "print(\"Scores for Imbalanced model\")\n",
    "print(recall_score(target_test,prediction))\n",
    "# Print the ROC/AUC score\n",
    "print(roc_auc_score(target_test,prediction))\n",
    "\n",
    "# Initialize the model\n",
    "model_depth_7_b = DecisionTreeClassifier(max_depth=7,class_weight=\"balanced\",random_state=42)\n",
    "# Fit it to the training component\n",
    "model_depth_7_b.fit(features_train,target_train)\n",
    "# Make prediction using test component\n",
    "prediction_b = model_depth_7_b.predict(features_test)\n",
    "\n",
    "print(\"Scores for Balanced model\")\n",
    "\n",
    "# Print the recall score for the balanced model\n",
    "print(recall_score(target_test,prediction_b))\n",
    "# Print the ROC/AUC score for the balanced model\n",
    "print(roc_auc_score(target_test,prediction_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85ba8def-8466-494f-a4e7-16d3f17e7b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98533333 0.98533333 0.974      0.96533333 0.96       0.97933333\n",
      " 0.99       0.99333333 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "\n",
    "# Import the function for implementing cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Use that function to print the cross validation score for 10 folds\n",
    "print(cross_val_score(model,features,target,cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15f9bb31-0c41-4a1e-a6fc-009e17a5deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up grid search parameters\n",
    "# Generate values for maximum depth\n",
    "depth = [i for i in range(5,21,1)]\n",
    "\n",
    "# Generate values for minimum sample size\n",
    "samples = [i for i in range(50,500,50)]\n",
    "\n",
    "# Create the dictionary with parameters to be checked\n",
    "parameters = dict(max_depth=depth, min_samples_leaf=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1d1722ca-7c2e-412f-a066-4c848c736033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_leaf': 50}\n"
     ]
    }
   ],
   "source": [
    "# import the GridSearchCV function\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# set up parameters: done\n",
    "parameters = dict(max_depth=depth, min_samples_leaf=samples)\n",
    "\n",
    "# initialize the param_search function using the GridSearchCV function, initial model and parameters above\n",
    "param_search = GridSearchCV(model, parameters, cv=3)\n",
    "\n",
    "# fit the param_search to the training dataset\n",
    "param_search.fit(features_train, target_train)\n",
    "\n",
    "# print the best parameters found\n",
    "print(param_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6405d669-2682-4800-8592-bb952fb93961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>satisfaction</th>\n",
       "      <td>0.551529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spend_company</th>\n",
       "      <td>0.157009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evaluation</th>\n",
       "      <td>0.144354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_projects</th>\n",
       "      <td>0.092864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_montly_hours</th>\n",
       "      <td>0.053087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technical</th>\n",
       "      <td>0.000631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr</th>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promotion</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_accident</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandD</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marketing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_mng</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IT</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      importance\n",
       "satisfaction            0.551529\n",
       "time_spend_company      0.157009\n",
       "evaluation              0.144354\n",
       "number_of_projects      0.092864\n",
       "average_montly_hours    0.053087\n",
       "technical               0.000631\n",
       "hr                      0.000295\n",
       "salary                  0.000231\n",
       "promotion               0.000000\n",
       "work_accident           0.000000\n",
       "RandD                   0.000000\n",
       "management              0.000000\n",
       "marketing               0.000000\n",
       "product_mng             0.000000\n",
       "sales                   0.000000\n",
       "support                 0.000000\n",
       "IT                      0.000000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting important features\n",
    "\n",
    "# Best Model \n",
    "model_best = DecisionTreeClassifier(max_depth=5, min_samples_leaf = 50 , random_state=42)\n",
    "# Fit it to the training component\n",
    "model_best.fit(features_train,target_train)\n",
    "\n",
    "# Calculate feature importances\n",
    "feature_importances = model_best.feature_importances_\n",
    "\n",
    "# Create a list of features: done\n",
    "feature_list = list(features)\n",
    "\n",
    "# Save the results inside a DataFrame using feature_list as an index\n",
    "relative_importances = pd.DataFrame(index=feature_list, data=feature_importances, columns=[\"importance\"])\n",
    "\n",
    "# Sort values to learn most important features\n",
    "relative_importances.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35ae0e12-93d4-420e-b622-0964709ad979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Important Features\n",
    "# select only features with relative importance higher than 1%\n",
    "selected_features = relative_importances[relative_importances.importance >0.01]\n",
    "\n",
    "# create a list from those features: done\n",
    "selected_list = selected_features.index\n",
    "\n",
    "# transform both features_train and features_test components to include only selected features\n",
    "features_train_selected = features_train[selected_list]\n",
    "features_test_selected = features_test[selected_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e7d240a-8113-45da-8380-88e96facc108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.46666666666667\n",
      "91.9732441471572\n",
      "92.95472582401672\n"
     ]
    }
   ],
   "source": [
    "# Develop and test the best model\n",
    "# Initialize the best model using parameters provided in description\n",
    "model_best = DecisionTreeClassifier(max_depth = 5, min_samples_leaf =50, class_weight = \"balanced\", random_state=42)\n",
    "\n",
    "# Fit the model using only selected features from training set: done\n",
    "model_best.fit(features_train_selected, target_train)\n",
    "\n",
    "# Make prediction based on selected list of features from test set\n",
    "prediction_best = model_best.predict(features_test_selected)\n",
    "\n",
    "# Print the general accuracy of the model_best\n",
    "print(model_best.score(features_test_selected, target_test) * 100)\n",
    "\n",
    "# Print the recall score of the model predictions\n",
    "print(recall_score(target_test, prediction_best) * 100)\n",
    "\n",
    "# Print the ROC/AUC score of the model predictions\n",
    "print(roc_auc_score(target_test, prediction_best) * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a6ca3-02d1-46d3-80a7-c1bf6f6625be",
   "metadata": {},
   "source": [
    "# Insights and Recommendations\n",
    "\n",
    "## 1. Departments with High Attrition: \n",
    "Departments such as accounting, IT, and support exhibit higher attrition rates. These departments should be the focus of targeted retention strategies to address underlying issues such as job satisfaction and workload.\n",
    "\n",
    "## 2. Impact of Salary on Attrition: \n",
    "While salary is a factor in attrition, it is not the most significant predictor. Efforts to improve retention should focus more on factors such as job satisfaction and employee evaluations.\n",
    "\n",
    "## 3. Employee Satisfaction:\n",
    "High attrition is strongly linked to low satisfaction levels. \n",
    "Initiatives to improve job satisfaction, such as providing growth opportunities, recognizing employee achievements, and fostering a positive work environment, could help reduce attrition.\n",
    "\n",
    "## 4. Workload Management:\n",
    "The number of projects and average monthly hours are significant predictors of attrition. Balancing workloads and ensuring employees are not overburdened can help in retaining employees.\n",
    "\n",
    "## 5. Targeted Retention Strategies:\n",
    "Develop tailored strategies for high-attrition departments, focusing on improving job satisfaction and work conditions.\n",
    "Consider reviewing and adjusting salary structures, especially for lower salary levels, to ensure they are competitive and fair.\n",
    "\n",
    "These insights and recommendations can help the company address the root causes of attrition and implement effective strategies to improve employee retention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
